{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3685428",
   "metadata": {},
   "source": [
    "# üè• AI-Based Medical Diagnosis Assistant\n",
    "\n",
    "## Complete ML Pipeline with Explainable AI (SHAP)\n",
    "\n",
    "This notebook implements an end-to-end medical AI system that:\n",
    "- Predicts disease risk probability from patient data\n",
    "- Identifies top contributing factors (explainable AI)\n",
    "- Handles class imbalance with SMOTE\n",
    "- Compares Logistic Regression, Random Forest, and XGBoost models\n",
    "- Uses SHAP for local and global explainability\n",
    "- Prepares models for Streamlit deployment\n",
    "\n",
    "**Date**: February 2026  \n",
    "**Purpose**: Educational & Research Use Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ff8601",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries\n",
    "\n",
    "Import all necessary packages for data processing, ML modeling, and explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path to import custom modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_recall_curve, roc_auc_score, \n",
    "    roc_curve, auc, f1_score, classification_report\n",
    ")\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Imbalance handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Explainability\n",
    "import shap\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "print(f\"SHAP version: {shap.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b1d11",
   "metadata": {},
   "source": [
    "## Section 2: Load and Explore Medical Dataset\n",
    "\n",
    "Load the medical dataset containing symptoms, vitals, and lab values. Perform exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6015fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom modules\n",
    "from src.data_generator import generate_medical_dataset\n",
    "from src.data_processor import MedicalDataProcessor, prepare_data\n",
    "\n",
    "# Generate dataset (or load if exists)\n",
    "data_path = Path(\"../data/medical_data_single_disease.csv\")\n",
    "\n",
    "if data_path.exists():\n",
    "    print(f\"Loading dataset from {data_path}\")\n",
    "    df = pd.read_csv(data_path)\n",
    "else:\n",
    "    print(\"Generating synthetic medical dataset...\")\n",
    "    df = generate_medical_dataset(n_samples=2000, imbalance_ratio=0.15)\n",
    "    data_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(data_path, index=False)\n",
    "    print(f\"Dataset saved to {data_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa98c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TARGET VARIABLE DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "target_counts = df['disease_risk'].value_counts()\n",
    "print(target_counts)\n",
    "print(f\"\\nDisease Prevalence: {df['disease_risk'].mean():.2%}\")\n",
    "print(f\"Class Imbalance Ratio: {target_counts[0]/target_counts[1]:.2f}:1\")\n",
    "\n",
    "# Visualize class distribution\n",
    "fig = px.pie(\n",
    "    values=target_counts.values,\n",
    "    names=['Healthy', 'Disease'],\n",
    "    title='Target Variable Distribution',\n",
    "    color_discrete_map={'Healthy': '#2ca02c', 'Disease': '#d62728'}\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\n{'Missing Values:':30} {df.isnull().sum().sum()}\")\n",
    "print(f\"{'Data Types:':30} {df.dtypes.nunique()} unique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c317e",
   "metadata": {},
   "source": [
    "## Section 3: Data Preprocessing and Feature Engineering\n",
    "\n",
    "Clean data, normalize features, and create engineered features from symptoms, vitals, and lab values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dea864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and preprocess data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA PREPROCESSING & FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train, X_test, y_train, y_test, processor = prepare_data(\n",
    "    df,\n",
    "    target_column='disease_risk',\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nFeatures after engineering: {X_train.shape[1]}\")\n",
    "print(f\"New features added: {X_train.shape[1] - (len(df.columns) - 1)}\")\n",
    "\n",
    "# Show feature names\n",
    "print(f\"\\nFeature names:\\n{X_train.columns.tolist()}\")\n",
    "\n",
    "# Visualize feature distributions\n",
    "print(\"\\nFeature Statistics (Training Set):\")\n",
    "print(X_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5a4bee",
   "metadata": {},
   "source": [
    "## Section 4: Handle Class Imbalance with SMOTE\n",
    "\n",
    "Apply SMOTE (Synthetic Minority Over-sampling Technique) to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f78aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate SMOTE\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASS IMBALANCE HANDLING - SMOTE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nOriginal Training Set Distribution:\")\n",
    "print(f\"Class 0 (Healthy): {np.sum(y_train == 0)} ({np.mean(y_train == 0):.1%})\")\n",
    "print(f\"Class 1 (Disease): {np.sum(y_train == 1)} ({np.mean(y_train == 1):.1%})\")\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train.values, y_train.values)\n",
    "\n",
    "print(f\"\\nAfter SMOTE (for XGBoost training):\")\n",
    "print(f\"Class 0 (Healthy): {np.sum(y_train_smote == 0)} ({np.mean(y_train_smote == 0):.1%})\")\n",
    "print(f\"Class 1 (Disease): {np.sum(y_train_smote == 1)} ({np.mean(y_train_smote == 1):.1%})\")\n",
    "print(f\"\\nTotal samples: {len(y_train_smote)} (increased from {len(y_train)})\")\n",
    "\n",
    "# Visualization\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(name='Before SMOTE', x=['Healthy', 'Disease'], y=[np.sum(y_train==0), np.sum(y_train==1)]))\n",
    "fig.add_trace(go.Bar(name='After SMOTE', x=['Healthy', 'Disease'], y=[np.sum(y_train_smote==0), np.sum(y_train_smote==1)]))\n",
    "fig.update_layout(title='Class Distribution: Before vs After SMOTE', barmode='group', height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973fec7d",
   "metadata": {},
   "source": [
    "## Section 5: Train Logistic Regression Model (Baseline)\n",
    "\n",
    "Build and train a Logistic Regression baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b5b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import LogisticRegressionModel\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL 1: LOGISTIC REGRESSION (BASELINE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train model\n",
    "lr_model = LogisticRegressionModel(max_iter=1000)\n",
    "lr_model.train(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_lr, y_proba_lr = lr_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"\\nModel Metrics:\")\n",
    "print(f\"  ROC-AUC: {lr_model.model_metrics['roc_auc']:.4f}\")\n",
    "print(f\"  PR-AUC: {lr_model.model_metrics['pr_auc']:.4f}\")\n",
    "print(f\"  F1-Score: {lr_model.model_metrics['f1_score']:.4f}\")\n",
    "\n",
    "# ROC Curve\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)\n",
    "fig_roc = go.Figure()\n",
    "fig_roc.add_trace(go.Scatter(x=fpr_lr, y=tpr_lr, mode='lines', name=f'Logistic Regression (AUC={lr_model.model_metrics[\"roc_auc\"]:.3f})'))\n",
    "fig_roc.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Random Classifier'))\n",
    "fig_roc.update_layout(title='ROC Curve - Logistic Regression', xaxis_title='False Positive Rate', yaxis_title='True Positive Rate')\n",
    "fig_roc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4aaef",
   "metadata": {},
   "source": [
    "## Section 6: Train Random Forest Model\n",
    "\n",
    "Implement and train a Random Forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3828e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import RandomForestModel, get_feature_importance\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL 2: RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train model\n",
    "rf_model = RandomForestModel(n_estimators=100, max_depth=15)\n",
    "rf_model.train(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_rf, y_proba_rf = rf_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"\\nModel Metrics:\")\n",
    "print(f\"  ROC-AUC: {rf_model.model_metrics['roc_auc']:.4f}\")\n",
    "print(f\"  PR-AUC: {rf_model.model_metrics['pr_auc']:.4f}\")\n",
    "print(f\"  F1-Score: {rf_model.model_metrics['f1_score']:.4f}\")\n",
    "\n",
    "# Feature Importance\n",
    "importance_df = get_feature_importance(rf_model, feature_names=X_train.columns, top_n=10)\n",
    "\n",
    "# Plot feature importance\n",
    "fig_imp = go.Figure()\n",
    "fig_imp.add_trace(go.Bar(\n",
    "    x=importance_df['importance'],\n",
    "    y=importance_df['feature'],\n",
    "    orientation='h'\n",
    "))\n",
    "fig_imp.update_layout(title='Top 10 Important Features - Random Forest', \n",
    "                     xaxis_title='Importance', yaxis_title='Feature', height=400)\n",
    "fig_imp.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)\n",
    "fig_roc = go.Figure()\n",
    "fig_roc.add_trace(go.Scatter(x=fpr_rf, y=tpr_rf, mode='lines', name=f'Random Forest (AUC={rf_model.model_metrics[\"roc_auc\"]:.3f})'))\n",
    "fig_roc.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Random Classifier'))\n",
    "fig_roc.update_layout(title='ROC Curve - Random Forest', xaxis_title='False Positive Rate', yaxis_title='True Positive Rate')\n",
    "fig_roc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63604e2",
   "metadata": {},
   "source": [
    "## Section 7: Train XGBoost Model with SMOTE\n",
    "\n",
    "Build and train an XGBoost model with SMOTE balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import XGBoostModel\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL 3: XGBOOST WITH SMOTE (BEST PERFORMANCE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train model with SMOTE\n",
    "xgb_model = XGBoostModel(n_estimators=150, max_depth=5, learning_rate=0.1)\n",
    "xgb_model.train(X_train, y_train, apply_smote=True)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_xgb, y_proba_xgb = xgb_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"\\nModel Metrics:\")\n",
    "print(f\"  ROC-AUC: {xgb_model.model_metrics['roc_auc']:.4f}\")\n",
    "print(f\"  PR-AUC: {xgb_model.model_metrics['pr_auc']:.4f}\")\n",
    "print(f\"  F1-Score: {xgb_model.model_metrics['f1_score']:.4f}\")\n",
    "\n",
    "# Feature Importance\n",
    "importance_df_xgb = get_feature_importance(xgb_model, feature_names=X_train.columns, top_n=10)\n",
    "\n",
    "# Plot feature importance\n",
    "fig_imp_xgb = go.Figure()\n",
    "fig_imp_xgb.add_trace(go.Bar(\n",
    "    x=importance_df_xgb['importance'],\n",
    "    y=importance_df_xgb['feature'],\n",
    "    orientation='h',\n",
    "    marker_color='#ff7f0e'\n",
    "))\n",
    "fig_imp_xgb.update_layout(title='Top 10 Important Features - XGBoost', \n",
    "                          xaxis_title='Importance', yaxis_title='Feature', height=400)\n",
    "fig_imp_xgb.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_proba_xgb)\n",
    "fig_roc_xgb = go.Figure()\n",
    "fig_roc_xgb.add_trace(go.Scatter(x=fpr_xgb, y=tpr_xgb, mode='lines', name=f'XGBoost (AUC={xgb_model.model_metrics[\"roc_auc\"]:.3f})'))\n",
    "fig_roc_xgb.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Random Classifier'))\n",
    "fig_roc_xgb.update_layout(title='ROC Curve - XGBoost', xaxis_title='False Positive Rate', yaxis_title='True Positive Rate')\n",
    "fig_roc_xgb.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d097d12",
   "metadata": {},
   "source": [
    "## Section 8: Model Evaluation & Precision-Recall Optimization\n",
    "\n",
    "Calculate precision-recall curves and find optimal decision thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253aee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processor import calculate_precision_recall_metrics\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRECISION-RECALL OPTIMIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate PR metrics for different thresholds\n",
    "thresholds_to_test = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "print(\"\\nOptimal Threshold Analysis (XGBoost):\")\n",
    "print(f\"{'Threshold':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
    "print(\"-\" * 48)\n",
    "\n",
    "pr_metrics, pr_auc, (precision, recall, pr_thresholds) = calculate_precision_recall_metrics(\n",
    "    y_test, y_proba_xgb, thresholds=thresholds_to_test\n",
    ")\n",
    "\n",
    "for metric in pr_metrics:\n",
    "    print(f\"{metric['threshold']:<12.1f} {metric['precision']:<12.4f} {metric['recall']:<12.4f} {metric['f1']:<12.4f}\")\n",
    "\n",
    "# Precision-Recall Curve\n",
    "fig_pr = go.Figure()\n",
    "fig_pr.add_trace(go.Scatter(\n",
    "    x=recall, y=precision, mode='lines', fill='tozeroy',\n",
    "    name=f'XGBoost (PR-AUC={pr_auc:.3f})', line=dict(color='red')\n",
    "))\n",
    "fig_pr.update_layout(\n",
    "    title='Precision-Recall Curve - XGBoost',\n",
    "    xaxis_title='Recall (Sensitivity)',\n",
    "    yaxis_title='Precision',\n",
    "    xaxis=dict(range=[0, 1]),\n",
    "    yaxis=dict(range=[0, 1])\n",
    ")\n",
    "fig_pr.show()\n",
    "\n",
    "# Recommendation\n",
    "print(f\"\\n‚úÖ Recommended Threshold: 0.5 (balanced precision-recall)\")\n",
    "print(f\"   At threshold 0.5: Precision={pr_metrics[2]['precision']:.3f}, Recall={pr_metrics[2]['recall']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d44fe",
   "metadata": {},
   "source": [
    "## Section 9: Generate SHAP Explainability Values\n",
    "\n",
    "Use SHAP to explain predictions and identify contributing factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.explainability import ModelExplainer\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SHAP EXPLAINABILITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create explainer for XGBoost\n",
    "X_background = X_train.iloc[:min(100, len(X_train))]\n",
    "explainer = ModelExplainer(xgb_model, X_background, feature_names=X_train.columns.tolist())\n",
    "explainer.create_explainer(explainer_type='tree')\n",
    "\n",
    "print(\"\\nGenerating SHAP values for test set...\")\n",
    "shap_values = explainer.explain_dataset(X_test, max_samples=200)\n",
    "\n",
    "# Get feature importance from SHAP\n",
    "print(\"\\nGlobal Feature Importance (from SHAP):\")\n",
    "shap_importance = explainer.get_feature_importance_from_shap(top_n=10)\n",
    "print(shap_importance)\n",
    "\n",
    "# Example: Explain a high-risk prediction\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLE: EXPLAINING HIGH-RISK PATIENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find a high-risk misclassified patient\n",
    "high_risk_idx = np.where((y_proba_xgb > 0.7) & (y_test == 1))[0]\n",
    "if len(high_risk_idx) > 0:\n",
    "    idx = high_risk_idx[0]\n",
    "    explanation = explainer.explain_prediction(X_test.iloc[idx:idx+1], top_features=5)\n",
    "    \n",
    "    print(f\"\\nPatient Index: {X_test.index[idx]}\")\n",
    "    print(f\"Predicted Risk: {explanation['prediction_probability']:.1%}\")\n",
    "    print(f\"True Label: {'Disease' if y_test.iloc[idx] == 1 else 'Healthy'}\")\n",
    "    \n",
    "    print(f\"\\nTop Contributing Factors:\")\n",
    "    for i, factor in enumerate(explanation['top_contributing_factors'], 1):\n",
    "        print(f\"  {i}. {factor['feature']}\")\n",
    "        print(f\"     Value: {factor['feature_value']:.2f}\")\n",
    "        print(f\"     SHAP Value: {factor['shap_value']:.4f} ({factor['direction'].replace('_', ' ')})\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731f82ee",
   "metadata": {},
   "source": [
    "## Section 10: Compare Model Performance\n",
    "\n",
    "Create comparison metrics across all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = {\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost + SMOTE'],\n",
    "    'ROC-AUC': [\n",
    "        lr_model.model_metrics['roc_auc'],\n",
    "        rf_model.model_metrics['roc_auc'],\n",
    "        xgb_model.model_metrics['roc_auc']\n",
    "    ],\n",
    "    'PR-AUC': [\n",
    "        lr_model.model_metrics['pr_auc'],\n",
    "        rf_model.model_metrics['pr_auc'],\n",
    "        xgb_model.model_metrics['pr_auc']\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        lr_model.model_metrics['f1_score'],\n",
    "        rf_model.model_metrics['f1_score'],\n",
    "        xgb_model.model_metrics['f1_score']\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + df_comparison.to_string(index=False))\n",
    "\n",
    "# Radar chart\n",
    "fig_radar = go.Figure()\n",
    "\n",
    "for idx, model_name in enumerate(df_comparison['Model']):\n",
    "    fig_radar.add_trace(go.Scatterpolar(\n",
    "        r=[df_comparison.loc[idx, 'ROC-AUC'],\n",
    "           df_comparison.loc[idx, 'PR-AUC'],\n",
    "           df_comparison.loc[idx, 'F1-Score']],\n",
    "        theta=['ROC-AUC', 'PR-AUC', 'F1-Score'],\n",
    "        fill='toself',\n",
    "        name=model_name\n",
    "    ))\n",
    "\n",
    "fig_radar.update_layout(\n",
    "    polar=dict(radialaxis=dict(visible=True, range=[0.7, 1])),\n",
    "    title='Model Performance Comparison (Radar Chart)',\n",
    "    height=600\n",
    ")\n",
    "fig_radar.show()\n",
    "\n",
    "# Bar chart\n",
    "fig_bar = go.Figure()\n",
    "fig_bar.add_trace(go.Bar(x=df_comparison['Model'], y=df_comparison['ROC-AUC'], name='ROC-AUC'))\n",
    "fig_bar.add_trace(go.Bar(x=df_comparison['Model'], y=df_comparison['PR-AUC'], name='PR-AUC'))\n",
    "fig_bar.add_trace(go.Bar(x=df_comparison['Model'], y=df_comparison['F1-Score'], name='F1-Score'))\n",
    "fig_bar.update_layout(barmode='group', title='Model Metrics Comparison', height=400)\n",
    "fig_bar.show()\n",
    "\n",
    "# Best model\n",
    "best_idx = df_comparison['ROC-AUC'].idxmax()\n",
    "print(f\"\\nüèÜ Best Model: {df_comparison.loc[best_idx, 'Model']} (ROC-AUC: {df_comparison.loc[best_idx, 'ROC-AUC']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01177458",
   "metadata": {},
   "source": [
    "## Section 11: Create Prediction Function\n",
    "\n",
    "Develop a prediction function with risk factors for user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d496e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_disease_risk(patient_data):\n",
    "    \"\"\"\n",
    "    Predict disease risk for a patient\n",
    "    \n",
    "    Input: Dict with patient symptoms, vitals, and lab values\n",
    "    Output: Dict with risk probability and contributing factors\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame\n",
    "    patient_df = pd.DataFrame([patient_data])\n",
    "    \n",
    "    # Preprocess\n",
    "    patient_scaled = processor.add_interaction_features(patient_df)\n",
    "    \n",
    "    # Get predictions from all models\n",
    "    y_proba_lr = lr_model.predict_proba(patient_scaled)[0, 1]\n",
    "    y_proba_rf = rf_model.predict_proba(patient_scaled)[0, 1]\n",
    "    y_proba_xgb = xgb_model.predict_proba(patient_scaled)[0, 1]\n",
    "    \n",
    "    # Ensemble average\n",
    "    ensemble_prob = np.mean([y_proba_lr, y_proba_rf, y_proba_xgb])\n",
    "    \n",
    "    # Get SHAP explanation\n",
    "    explanation = explainer.explain_prediction(patient_scaled, top_features=5)\n",
    "    \n",
    "    # Categorize risk\n",
    "    if ensemble_prob < 0.3:\n",
    "        risk_level = \"LOW\"\n",
    "    elif ensemble_prob < 0.7:\n",
    "        risk_level = \"MEDIUM\"\n",
    "    else:\n",
    "        risk_level = \"HIGH\"\n",
    "    \n",
    "    return {\n",
    "        'ensemble_probability': ensemble_prob,\n",
    "        'risk_level': risk_level,\n",
    "        'individual_predictions': {\n",
    "            'logistic_regression': y_proba_lr,\n",
    "            'random_forest': y_proba_rf,\n",
    "            'xgboost': y_proba_xgb\n",
    "        },\n",
    "        'top_contributing_factors': explanation['top_contributing_factors']\n",
    "    }\n",
    "\n",
    "# Example prediction\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLE: PREDICT FOR NEW PATIENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "example_patient = {\n",
    "    'chest_pain_severity': 5,\n",
    "    'shortness_of_breath': 35,\n",
    "    'fatigue_level': 40,\n",
    "    'dizziness': 25,\n",
    "    'headache_frequency': 15,\n",
    "    'nausea_level': 20,\n",
    "    'systolic_bp': 145,\n",
    "    'diastolic_bp': 95,\n",
    "    'heart_rate': 92,\n",
    "    'body_temperature': 37.2,\n",
    "    'respiratory_rate': 18,\n",
    "    'oxygen_saturation': 96,\n",
    "    'cholesterol_total': 240,\n",
    "    'ldl_cholesterol': 160,\n",
    "    'hdl_cholesterol': 35,\n",
    "    'triglycerides': 180,\n",
    "    'glucose_fasting': 140,\n",
    "    'hemoglobin_a1c': 7.2,\n",
    "    'creatinine': 1.1,\n",
    "    'white_blood_cells': 7.5\n",
    "}\n",
    "\n",
    "result = predict_disease_risk(example_patient)\n",
    "\n",
    "print(f\"\\nPatient Risk Assessment:\")\n",
    "print(f\"  Ensemble Probability: {result['ensemble_probability']:.1%}\")\n",
    "print(f\"  Risk Level: {result['risk_level']}\")\n",
    "print(f\"\\nIndividual Model Predictions:\")\n",
    "print(f\"  Logistic Regression: {result['individual_predictions']['logistic_regression']:.1%}\")\n",
    "print(f\"  Random Forest: {result['individual_predictions']['random_forest']:.1%}\")\n",
    "print(f\"  XGBoost: {result['individual_predictions']['xgboost']:.1%}\")\n",
    "print(f\"\\nTop Contributing Risk Factors:\")\n",
    "for i, factor in enumerate(result['top_contributing_factors'], 1):\n",
    "    print(f\"  {i}. {factor['feature']}: {factor['feature_value']:.2f} ({factor['direction']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23058416",
   "metadata": {},
   "source": [
    "## Section 12: Prepare Model for Streamlit Deployment\n",
    "\n",
    "Save models and create helper functions for dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1685a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import save_model\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPARING FOR DEPLOYMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create models directory\n",
    "models_dir = Path(\"../models\")\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "print(\"\\nSaving trained models...\")\n",
    "save_model(lr_model, models_dir / \"logistic_regression_model.pkl\")\n",
    "save_model(rf_model, models_dir / \"random_forest_model.pkl\")\n",
    "save_model(xgb_model, models_dir / \"xgboost_model.pkl\")\n",
    "\n",
    "print(\"‚úÖ Models saved successfully!\")\n",
    "print(f\"Location: {models_dir.absolute()}\")\n",
    "\n",
    "# Create deployment configuration\n",
    "deployment_config = {\n",
    "    'model_type': 'medical_diagnosis_ensemble',\n",
    "    'version': '1.0.0',\n",
    "    'date': pd.Timestamp.now().isoformat(),\n",
    "    'models': {\n",
    "        'logistic_regression': {\n",
    "            'type': 'LogisticRegression',\n",
    "            'roc_auc': float(lr_model.model_metrics['roc_auc']),\n",
    "            'f1_score': float(lr_model.model_metrics['f1_score'])\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'type': 'RandomForestClassifier',\n",
    "            'roc_auc': float(rf_model.model_metrics['roc_auc']),\n",
    "            'f1_score': float(rf_model.model_metrics['f1_score'])\n",
    "        },\n",
    "        'xgboost': {\n",
    "            'type': 'XGBClassifier',\n",
    "            'roc_auc': float(xgb_model.model_metrics['roc_auc']),\n",
    "            'f1_score': float(xgb_model.model_metrics['f1_score'])\n",
    "        }\n",
    "    },\n",
    "    'features': X_train.columns.tolist(),\n",
    "    'ensemble_method': 'average',\n",
    "    'recommended_threshold': 0.5\n",
    "}\n",
    "\n",
    "# Save config\n",
    "config_path = models_dir / \"deployment_config.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(deployment_config, f, indent=2)\n",
    "\n",
    "print(f\"Config saved to {config_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NEXT STEPS FOR DEPLOYMENT\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. Run Streamlit Dashboard:\n",
    "   streamlit run ../app.py\n",
    "\n",
    "2. Access at:\n",
    "   http://localhost:8501\n",
    "\n",
    "3. Features Available:\n",
    "   - Single Patient Prediction\n",
    "   - Batch Predictions (CSV upload)\n",
    "   - Model Comparison\n",
    "   - Dataset Exploration\n",
    "   - SHAP Explanations\n",
    "\n",
    "4. For Production Deployment:\n",
    "   - Use FastAPI or Flask wrapper\n",
    "   - Containerize with Docker\n",
    "   - Deploy on cloud (AWS, GCP, Azure)\n",
    "   - Set up monitoring and logging\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
